# 📚 Book Scraping and Database Storage

Welcome to the **Book Scraping and Database Storage** project! This project scrapes book data from [Books to Scrape](https://books.toscrape.com/), stores the information in a **SQLite** database, and provides a simple, clean interface to inspect the data. If you're looking to scrape books for a project or just want to learn how to use web scraping with Python, this is the perfect starting point.

---

## 🚀 Project Overview

This project scrapes details such as the title, price, and URL of books from the **Books to Scrape** website and stores them in an **SQLite** database. You can easily expand this project by adding more scraping features, including pagination or even exporting the data to CSV or JSON formats.

### Key Features:

- **Web Scraping**: Scrape top books with basic details like title, price, and URL.
- **SQLite Database**: Store and manage scraped data in a local SQLite database.
- **Easy Export**: Data is easily accessible and can be exported as needed.

---

## 🛠️ Technologies Used

- **Python 3.x** – Programming language
- **BeautifulSoup** – For parsing HTML and scraping data
- **Requests** – For making HTTP requests
- **SQLAlchemy** – For handling database operations
- **SQLite** – A lightweight database for storing scraped data

---

## 💡 Installation and Setup

### 1. Clone the repository:

git clone https://github.com/Sahash-Rai/Webscraper-To-Sqlite.git

## 2. Set up a virtual environment:

For macOS:

python3 -m venv venv
source venv/bin/activate

For Windows:

python -m venv venv
.\venv\Scripts\activate
### 3. Install the required dependencies:

pip install -r requirements.txt
🏃‍♂️ Running the Project
To start the web scraping process, simply run the main script.





